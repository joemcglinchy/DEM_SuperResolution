{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook looks at loading image chips, resizing appropriately, and storing as PyTorch data loaders. Or... at least a set of tensors. DataLoader is preferable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import some required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import glob\n",
    "import os,sys\n",
    "from skimage.transform import resize\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import rasterio\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the image file names for training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 84090\n",
      "84091 112121\n",
      "112121 140151\n",
      "140152\n"
     ]
    }
   ],
   "source": [
    "# specify the image directories for dg and planet data\n",
    "dg_dir = '/media/jomc9287/Data/pytorch_SSIR_jdiaz/dg_sr_chips'\n",
    "planet_dir = '/media/jomc9287/Data/pytorch_SSIR_jdiaz/planet_sr_chips'\n",
    "\n",
    "# get the tif file paths\n",
    "dg_files = glob.glob(dg_dir + '/*.tif')\n",
    "planet_files = glob.glob(planet_dir + '/*.tif')\n",
    "\n",
    "# ensure these are the same lengths\n",
    "assert(len(dg_files) == len(planet_files))\n",
    "\n",
    "# get the values for train/test/validation splits\n",
    "file_len = len(dg_files)\n",
    "train_len = int(file_len*.6)\n",
    "test_len = int((file_len - train_len) / 2 )\n",
    "validation_len = file_len - train_len - test_len\n",
    "\n",
    "train_list = list(range(train_len))\n",
    "test_list = list(range(train_len, train_len+test_len+1))\n",
    "val_list = list(range(train_len+test_len, file_len))\n",
    "\n",
    "print(train_list[0], train_list[-1])\n",
    "print(test_list[0], test_list[-1])\n",
    "print(val_list[0], val_list[-1])\n",
    "print(file_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a function that will return relevant information from the image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDims(fi):\n",
    "    \n",
    "    with rasterio.open(fi, 'r') as src:\n",
    "        transform =src.transform\n",
    "        arr = src.read()\n",
    "        \n",
    "    return transform, arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a class for digital globe data which will do the following:\n",
    "1. extract the image based on an index\n",
    "2. extract the blue-green-red-nir channels\n",
    "3. resize it be exactly 3x the planet data. The planet data is 10x10, so this should be 30x30\n",
    "4. divide by the reflectance precision factor of 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jomc9287/anaconda3/envs/pytorch35/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: The value of this property will change in version 1.0. Please see https://github.com/mapbox/rasterio/issues/86 for details.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe3c66e86a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHBNJREFUeJztnVuMXWd1x//rXGfmzJy52uOxPb7GTUouBGoMVVAVCkRpGynwACKtIFUR5oFIoPJQlIeSl6pRxaU8ICTTRAQJAkjc8pCW0LQ0DaKpJyaNQ0zAiceX8XgunvvtXPZZfZjjdjI5a+1jz/icCd//J0UZ73W+/X37O/u/9znnv9f6RFVBCAmPRLMHQAhpDhQ/IYFC8RMSKBQ/IYFC8RMSKBQ/IYFC8RMSKBQ/IYFC8RMSKKmNNBaRuwF8BUASwD+p6sNuZ605TXf21IxpMq4zO6TeJSxhP8GYWHZ2CiC1YrfVpN02yrq7dfGORVPO05hJJ6b+caLsxL2mqYq/Xw9vTF5I/CdSteI09o7T223M9Llz77X1+ox78NY4T8qT04jmF+NGDGAD4heRJICvAng/gAsAjovIE6r6stUm3dmDAx/765qxcrvfX5SxZyNqtWOVjrIZy7+UcfvsfqVkxspttkqnfy/uSmZTztnHUuyNzFiys2jGKiX/A15iwp6HSta5ePbYfQKA9+S4lp0xORfsdNZ+PwGguJS2dzvtxIq2XuJuTFGXMybvAum9L95FDIC01u5z9G+/6rZby0Y+9h8BcFpVX1PVIoDvALh3A/sjhDSQjYh/F4Dza/59obqNEPImYCPir/W55A2f10TkqIgMichQtLy4ge4IIZvJRsR/AcDgmn/vBnBx/YtU9ZiqHlbVw8nW3Aa6I4RsJhsR/3EAh0Rkv4hkAHwEwBObMyxCyPXmmn/tV9WyiDwA4CdYtfoeVdVf+Y2AhP9jrd3U+cW10mb/Ci4Fu2H7iN0OALKXV8xYsdP+FOO6D/YPzgCAUpc9pnRXwW9sjSfml2PstI9zd++sGUvE2G4T8/YcqWP1tWRslyXO6pteubZT2jsvM5f9+Uuet9/UlT57vKX99rzv2THl9nl2pM+N18OGfH5VfRLAkxseBSGk4fAJP0ICheInJFAofkICheInJFAofkICheInJFA2ZPVdLVIBUku1fU+J8aLTaSfratL2Wbt/Yxu4HSfe8EDi66h026mGxZw9nkTBSfd1shMBIOVk5w1umzZjU4ttZmwhJqV3z3bbU373tlfN2PPTe9z9np2xvWhJ29luB/oum7Hlsv+gxNRylxnLztr3uoT9aAEiP/kTrRP2e5p0Hs2Y7rF3fOSWs26fUaX2sUym63+Qhnd+QgKF4ickUCh+QgKF4ickUCh+QgKF4ickUBpq9SEBRFnDdoqpVpqZsV+QP2/7NJl/e8GMlcsxtsjArWYoarHtM8/eUceyBIAVJwW54lh2XW3LZiyR8KvsdqTtAS+U7VLEo/Md7n6TM/bpFXXYqcv5tJ3q6s0BAPc8Sjj1Rr2U3qWd/vxl5u17aNY5bzOX7fc6Cb/P7W3zNbenY97rtfDOT0igUPyEBArFT0igUPyEBArFT0igUPyEBEpDrb6oBZi7sbbFo1nfosiO2kNtv2jbP3LzIXunCf/aV+i2bS6JbAun7GT8iV8wGC3Ddp/Dpe1mbHDvpBnrarWtMwAYW7KzF89M115YFQDmxv0FFsVZ5y/Xt2TGUomYSXLI9NjHulKwMx8z0/a54FWHBoBih93Wy1aNnPkZLXS6fT7/2301ty8VYlIQ18A7PyGBQvETEigUPyGBQvETEigUPyGBQvETEiiNLeCZqiDbX9viedfgsNv2wgG7MOPp7QNmLDlvt+v6tdsl2kftVK+UnUSHlR12O8nFZBJO21ZN+rL9dp1P9Jqxvh1zbpcVJxNuYb7FHs+kf/oknUKmS3nb0tzdMmPGWpNOpU0AsN1QVLbZ4ylV7Aw7q1jmFSb67AVJZ+bs+cvm7DTDw/lht8+flW+qHYjJjl3LhsQvIsMA5gFEAMqqengj+yOENI7NuPO/R1XtJ0wIIVsSfucnJFA2Kn4F8JSIPC8iR2u9QESOisiQiAxFc4sb7I4Qslls9GP/Hap6UUS2A/ipiPxaVZ9Z+wJVPQbgGAC0HNx1FT9HEEKuJxu686vqxer/xwH8EMCRzRgUIeT6c83iF5GciHRc+RvAXQBe2qyBEUKuLxv52N8P4IcicmU/31bVf/EaqAKlUm0/Nc6/PZSfMGPne2wvv5C1ffOZm/z0x0KvvShkZtZJVx22p1WP+L97DO4eM2OvXtpmxmTK9s1n51vdPpMpO51anNtDqd9/z0rOl7yU0+czYzeYsUuX/VRXiN1pd95JI07aabsaUzH4oLOw6GKnfY4tlezza7LkV0a+6/ba99kfOVWc13PN4lfV1wC89VrbE0KaC60+QgKF4ickUCh+QgKF4ickUCh+QgKlsQt1RglUDEvqfy7v9Js6aZXFMbsqqzguTdTnrNwIYNF21lAcsS2ctot2u1LMOpO3dtmNE46NdTrRZ8Y6cn713pkZOyVVLtkpqZLxH9jUDjt9OSraKbTjM3ZV4ErZn8CEc0aXI/scas/ai5Ue6LCtPADoz9op0xdWbBt6dMm2LS/GVO+9rf1Cze0/ScSkPK+Bd35CAoXiJyRQKH5CAoXiJyRQKH5CAoXiJyRQGlu9NwJS87WvNxOOvQMA6lh96Tk75i2GqJ3+4qA93XYG3lTStscKS3YWXdzVtj1pW07v7Bk2Y/mMbedNLPtzO322297vsFPxtt233Rb3OgtYdtiWVK7VtmDbuhbcPldKTkalk52XStjnwsE2O6MUAPrS82ZsqWJbwlMF+xxaLNtZmgBQqNTOCFTEeMlr4J2fkECh+AkJFIqfkECh+AkJFIqfkECh+AkJlMZm9QGwnIhtMRbOtlbbdjsZ2RmBlRXnEAt2ZhkALCzbdku21baqVnbY9k6HYykBQIuTlfXOtlfdtha/vOAvodgyas9Dasm2SqOWGFspax/rDTtt+2yfk0UXZ4GdmesxY+NTeTM2M+1Yt2VfJn8++N9m7GCLfZyTBduCjSto256sbe0m4J9fr38tISRIKH5CAoXiJyRQKH5CAoXiJyRQKH5CAoXiJyRQYn1+EXkUwD0AxlX1luq2HgDfBbAPwDCAD6vqdGxvCohhX3Zm/QqzN+btBSzPdNje7spZu3qqxhz9imdjl+zrZv607ZsvxlRl/VH2NjP2Wq9doXds2fawy06lXADI2FnEKLfak7C4y/eU23vshTErTurpxIrtf5fVPxYvpbcyZlci7jxtv59jO3e4fT7bcciMva/nZTO2p3XKjJ32SkcDOFforbm9GHdSr6GeO/83ANy9btvnADytqocAPF39NyHkTUSs+FX1GQDrL1H3Anis+vdjAD6wyeMihFxnrvU7f7+qjgJA9f/brReKyFERGRKRoWjRX5ueENI4rvsPfqp6TFUPq+rhZM5+fpoQ0liuVfxjIjIAANX/j2/ekAghjeBaxf8EgPurf98P4MebMxxCSKOox+p7HMCdAPpE5AKAzwN4GMD3ROTjAM4B+FA9nWkCqBgZmdMrdsVbABi6vMeMLSzYFg7a7ZTU9Jyfktpy3k7NTdkuFtJeGmy7b48NdsyYMc8C+9XIgBnzqtYCwMIBe0FN8RbG7PLTTnNZuwpvAvYcTTrVhudX/JTeYtm2Aiud9nEu7KldDRcANOUvSDpTtM/dQ5lLZuye3Bkz9mTrXrfPj+Una25/KrXstltLrPhV9T4j9N66eyGEbDn4hB8hgULxExIoFD8hgULxExIoFD8hgdLw6r0VwzYZG7Oz7wBAHcspsWAfhpTsdi2TvgWWWnQsHueyGaXrXyxxPSuRbTllErZV1eIsbpkQ36rq3mHbQ11ZO5YQ37b0jmVyyX7ac2LMznxMTvunbOTYebke+1jSvXb1aM8+BIAD7bVtNwBIS2TGSmq/LxmnHQBEWnvu1bFQ18M7PyGBQvETEigUPyGBQvETEigUPyGBQvETEiiNtfqSikp7bQsjNWZn0AExGXhOqORk9cWRcNyWsu1ioezULEnN+LbRqRG7WOSe7XbBx12ds+5+PQ44C2PenBsxY1YRySv8x+gNZmxi1LbzMqOO3Tnr26iLKfuU7thlF4k92GnPQRz7Wuy2wyW76OrLBTtD8UzBL+D594X+mtsvles/Dt75CQkUip+QQKH4CQkUip+QQKH4CQkUip+QQKH4CQmUhvr8yXSEnoHafvTCmO8Zt1+w/fpCt+39Fm6yvd25Hf61LzVqP3uQmbH7rDiPLMSlEZcKbWbsjLPgZn+/XfW3Le1X2R13qgKnxH7u4BeX9rv7nX3Jfk/bHL8+cooxe89QAIBm7DRjr4rxQsn23PMZvyLuK0u1PXcAGC3azzN4qdbjhQ63z5+fOVBz++WVE2671/Vf9ysJIb9TUPyEBArFT0igUPyEBArFT0igUPyEBEo9C3U+CuAeAOOqekt120MAPgFgovqyB1X1ybh9qQrKUW27KuEtCAkgtWJbOKWi3fYPD9iLIb49f87t8/Hhw2Zs8b/sVM2Mk12bKPopxlGLfSy6ZFt9ly7Z1Y/TLXZFWwCYabe9tRdHdpoxOe37brlR+1jKzrqshV77vU4WYs6TWXuOxifzdruE3efYkm2FAsBAbs6M5dttq3m+bM/7M6ftdGgPpyDwG6jnzv8NAHfX2P5lVb29+l+s8AkhW4tY8avqMwDsKhKEkDclG/nO/4CIvCgij4pI96aNiBDSEK5V/F8DcBDA7QBGAXzReqGIHBWRIREZiuaWrrE7Qshmc03iV9UxVY1UtQLg6wCOOK89pqqHVfVwMm8/t04IaSzXJH4RGVjzzw8CeGlzhkMIaRT1WH2PA7gTQJ+IXADweQB3isjtABTAMIBP1tNZQhTZdG3baanN9yhKbY5t5DhOuVTBjP3z2M1un9On7Ky0Ducn0IpT2Tc76x+nsxYnyjnbxipXnCzDSb8y8nSLbTkll5z7Q8ytY+6QbZ9VOuwDbe207bFEwp+/xWnbQ5RZ+40ZWbKtW4mxocfydube7E57PP2t82ZMI79PLRjngnMerCdW/Kp6X43Nj9TdAyFkS8In/AgJFIqfkECh+AkJFIqfkECh+AkJFIqfkEBpaPXedDLCjvba3uZEt52SCgBR1h5qdsr2fp86aXv56XHHkAeQP2vHkgWnmnCr7bUu9fvXW69yLZxqrwkn1dVbbRgAZPna7gGlHn/HLb121du2Fvv5i45s0YztcNJnAeBEcbcZS56zU3Mzzm4L/qmJyoI9f2dTPWasf6/t89+055Lb56lTxnFuckovIeR3EIqfkECh+AkJFIqfkECh+AkJFIqfkEBpqNUnADJGzmqy3V9Mspyzbbn8Wdty6h6y26U2UFjIXRy0x/Zbyq0xKb0le7+pZSdd086eRbnDCQLQlDOmtFNJt82vCiyONenRkrLPBev8uUK5aJ/SbU4adtuEM0fq3yPLnrU7Z6dTTzgLpGaTMXNrpRk7i5Guh3d+QgKF4ickUCh+QgKF4ickUCh+QgKF4ickUBpq9RWiFF6dql0lNa5aqWefLS3a17CEnSCGRORbUct99n7nb7DtxWSPnbGGMS9tD+gYtmPZWduOmt1vj7W0w8++y+TsScpkbMtpcd4/luU5e52GqNse7668nWI3suin2CXGbWsttWy/356b1z7iz9/MIbuqsmeVvjqyzYy1vOLPrfT59m098M5PSKBQ/IQECsVPSKBQ/IQECsVPSKBQ/IQESj0LdQ4C+CaAHVjNHTumql8RkR4A3wWwD6uLdX5YVae9fVUqguWCkWUXk4zkWTFJx87zFs2MYhY1LNrrLyLVZxenLBfsae0+5ffZ/+xlM6YZe79ze20LLNniZ4hls3YWXdLJzMu2+pmYpaTd1sv4G53Pm7H5pazbZ3bKPlFaZmzLrpK035fZg46VB6B066IZu7F/0oyNL9hZfQs5/zjRZ9jJqfotwHru/GUAn1XV3wfwLgCfEpG3APgcgKdV9RCAp6v/JoS8SYgVv6qOquqJ6t/zAE4B2AXgXgCPVV/2GIAPXK9BEkI2n6v6zi8i+wC8DcBzAPpVdRRYvUAA2L7ZgyOEXD/qFr+ItAP4PoDPqKq/csLr2x0VkSERGYrm7O9GhJDGUpf4RSSNVeF/S1V/UN08JiID1fgAgPFabVX1mKoeVtXDyXxuM8ZMCNkEYsUvIgLgEQCnVPVLa0JPALi/+vf9AH68+cMjhFwv6snquwPARwGcFJEXqtseBPAwgO+JyMcBnAPwoeszRELI9SBW/Kr6LGwX/r1X05mWBYXLrTVjSSctFwDS87YPW3Gqz3r+baX2UP6PzIwd0+O2R5tesMfTetn3YVd2dpixYpf9dqnzTkYL/oKkkePzv2OXvVppLuWkLgP4+eh+MzY9Zc/fdMk+mGg2ZnFV+/ELlNrsc2x5m1ON+Ta/zPONAzW/8a6OJ71ixmYLdtrufIwye7pr/342ntxcn58Q8jsIxU9IoFD8hAQKxU9IoFD8hAQKxU9IoDR2oc5IkJ6pnR7pWXkAkLQdE9emWd5lp7MmCv61r+M1O971ir3fUs5ut9jvp4fO7rfjxW7bQiz2Omm7MetlLi/Y6aPTRdsPHWiZdfc7mLfj6auwpNYyKbZFCAArvfb8ldqc82TQnr/3Hfyt2+dsybbspgp2BeNs0k4xjlr9+elvn6+5/TStPkJIHBQ/IYFC8RMSKBQ/IYFC8RMSKBQ/IYHSYKsPSM/VtlsyMbWBEmXbr1qpvfYnAODmt5w3YwtFv0Lq6NKAGctdsm2jpe32NXVhr2/FRD225ZTvsSsh9bfaXujoZacMMYDyvJ0pZy2sCgBvyV9y93tn3ytmbKSj24zNlW3rbDpvW2cA8EsMmrHSlP1+pzvtDMWutJ/VN3TJ7nNmyi5gk3aqKku3U5IadrZgUmj1EUJioPgJCRSKn5BAofgJCRSKn5BAofgJCZTGWn0VIG24VV7RSwBIlux4y6R9DStE9iHuz9uLYgLA6A32gpGXy3Z2WSVrj9Wz8gCgf4ddNfRApz3eXMq2hrIpv8+z0mPGEs6Cmkdyr7r7fUfWLmz5uN5mxiaL9tz+Qec5t8+FAdvOO7Wwy4yVp2x78fjkXrfP2bO2ldr1GzvLsNxqj7X9j8fcPhfKtdtWNGbF2zXwzk9IoFD8hAQKxU9IoFD8hAQKxU9IoFD8hAQKxU9IoMT6/CIyCOCbAHYAqAA4pqpfEZGHAHwCwET1pQ+q6pPevlSAipE9utLr+5NSseNJZ73IM7+0vd1zhd1un5lpu8+EXXgVi7uchTrzThliANtzC2ZszqkSO7ZsL/DZ22KnAgNAdsB+DmC5bKf7fmf8ne5+/zVrH8ui4VMDQEfKnqOlSsbt0/O5W3vsVTw7c3bsr/Y86/b55eX3mbHlGTt1OVGwx3ppxG4HALNn+2tuX5nz09TXUs9DPmUAn1XVEyLSAeB5EflpNfZlVf1C3b0RQrYM9SzRPQpgtPr3vIicAmDfTgkhbwqu6ju/iOwD8DYAz1U3PSAiL4rIoyJS83OKiBwVkSERGYqW/I+fhJDGUbf4RaQdwPcBfEZV5wB8DcBBALdj9ZPBF2u1U9VjqnpYVQ8n2+ySRoSQxlKX+EUkjVXhf0tVfwAAqjqmqpGqVgB8HcCR6zdMQshmEyt+EREAjwA4papfWrN9bXXLDwJ4afOHRwi5XtTza/8dAD4K4KSIvFDd9iCA+0TkdqwuAzkM4JNxO6pkFfMHDVsp7af0Jhbt1EhvQc3tx519Rte2WCQALPfYfapzSS2X/evtpQXbsitHdtvlgm2BLeZ8e6wza1trU4t2tdzXXqttN11BVpw5arHnPtdnV8s90OunYacS9n7vGDxjxv6i7xd2n2m/tPSTfXbq8nMD9vuJyLb6/uytJ90+n99V26ZOPu6nb6+lnl/7nwVQa5Sup08I2drwCT9CAoXiJyRQKH5CAoXiJyRQKH5CAqWx1XvLgsxUbcsuaomp3rvsZfXZbTNzdvqdpvxMQrXdRSRKTkPnkhqVnJ0CmJ61n4KMinZbXbJjK9N2NiAALG6zH7vOOJV/JeukNgKQBXtMiTk7tgjbXhxJexMP9LfbmYTbMvN2LGnPwcmisxIsgJSzOObOQdua7G21Lc27unyr757uF2pu/3TWrv68Ht75CQkUip+QQKH4CQkUip+QQKH4CQkUip+QQGmo1ZcoAh1mYpVvuyWcZCVnLUlELU5mme+6oZK0xxQ5dRLFccCiRbsgJgBoySka6hR89KhkfBu1ULBPgxudjLVDPZPufk912ll/i4u2/diSsd/sSiUmK3LezqI7oYNmzCsM+sJlv9Dr9FKrGTvUO2HG3tP7ihk7X+p1+3xXa+1FUj3bcT288xMSKBQ/IYFC8RMSKBQ/IYFC8RMSKBQ/IYFC8RMSKA31+SGAGj22Tfj+ZLJgx5e2XdthZGb8SqfL221PvtDjpBjbaz76pX0BpOfsuGfhrgzYDxdkttmpowDQl7fTWW/NXzRjuzNT/n4z9n7nnIU697ROm7Fnxw+6fZ49Z6ffTo/lzdiZvO2rV4b9xWa8t3QkWzRj6T77PfvZ1I1un+cKtcc7HT3ttlsL7/yEBArFT0igUPyEBArFT0igUPyEBArFT0igiKqf7rmpnYlMADi7ZlMfAD8vtLFwPD5bbTzA1htTs8ezV1W31fPChor/DZ2LDKnq4aYNYB0cj89WGw+w9ca01cbjwY/9hAQKxU9IoDRb/Mea3P96OB6frTYeYOuNaauNx6Sp3/kJIc2j2Xd+QkiTaIr4ReRuEXlFRE6LyOeaMYZ14xkWkZMi8oKIDDVpDI+KyLiIvLRmW4+I/FREflv9f3eTx/OQiIxU5+kFEfnTBo5nUET+XUROicivROTT1e1NmSNnPE2bo6ul4R/7RSQJ4DcA3g/gAoDjAO5T1ZcbOpDXj2kYwGFVbZo/KyJ/BGABwDdV9Zbqtn8AMKWqD1cvkt2q+jdNHM9DABZU9QuNGMO68QwAGFDVEyLSAeB5AB8A8Jdowhw54/kwmjRHV0sz7vxHAJxW1ddUtQjgOwDubcI4thSq+gyA9Qny9wJ4rPr3Y1g9uZo5nqahqqOqeqL69zyAUwB2oUlz5IznTUMzxL8LwPk1/76A5k+aAnhKRJ4XkaNNHsta+lV1FFg92QBsb/J4AOABEXmx+rWgYV9D1iIi+wC8DcBz2AJztG48wBaYo3pohvhrlcBptuVwh6q+HcCfAPhU9SMveSNfA3AQwO0ARgF8sdEDEJF2AN8H8BlVnWt0/3WMp+lzVC/NEP8FAGvXTdoNwK4V1QBU9WL1/+MAfojVryZbgbHqd8sr3zHttbMagKqOqWqkqhUAX0eD50lE0lgV2rdU9QfVzU2bo1rjafYcXQ3NEP9xAIdEZL+IZAB8BMATTRgHAEBEctUfbCAiOQB3AXjJb9UwngBwf/Xv+wH8uIljuSKuK3wQDZwnEREAjwA4papfWhNqyhxZ42nmHF0tTXnIp2p//COAJIBHVfXvGj6I/x/LAaze7YHVgqbfbsZ4RORxAHdiNStsDMDnAfwIwPcA7AFwDsCHVLUhP8IZ47kTqx9nFcAwgE9e+b7dgPG8G8B/AjgJ4Eop0wex+j274XPkjOc+NGmOrhY+4UdIoPAJP0ICheInJFAofkICheInJFAofkICheInJFAofkICheInJFD+F0TnRvfvdsL8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe3c66c7c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DigitalGlobeDataset(Dataset):\n",
    "    \"\"\"DG Dataset\"\"\"\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            image_dir(string): the folder containing the DG images\n",
    "            transform (callable, optional): Optional transform to  be applies\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.bgrn = [1,2,4,6]\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = glob.glob(self.image_dir + '/*.tif')[idx]\n",
    "        img_arr = getDims(img_name)[1]\n",
    "        \n",
    "        new_shp = [4,30,30]\n",
    "        img_arr = img_arr[self.bgrn,:,:] \n",
    "        img_arr = resize(img_arr, new_shp, preserve_range=True, mode='reflect')\n",
    "        img_arr = img_arr / 10000\n",
    "        \n",
    "        if self.transform:\n",
    "            img_arr = self.transform(img_arr)\n",
    "        \n",
    "        return img_arr\n",
    "    \n",
    "dg_dataset = DigitalGlobeDataset(dg_dir)\n",
    "sample = dg_dataset[1]\n",
    "plt.imshow(sample[0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a class for planetScope data which will do the following:\n",
    "1. extract the image based on an index\n",
    "2. divide by the reflectance precision factor of 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jomc9287/anaconda3/envs/pytorch35/lib/python3.5/site-packages/ipykernel_launcher.py:15: FutureWarning: The value of this property will change in version 1.0. Please see https://github.com/mapbox/rasterio/issues/86 for details.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe3c66369b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADEdJREFUeJzt3d9v3XUdx/HXa+d0XbvfCIprJxtK0IWoYGNAokbgwl+RC43BBI3ezBh/oDEx6A3/gBK9MJqJeiORxEHUKFFM1ES9WCzbIm4VMweMyoZTxn60q13btxetyQTW8y39fPy27zwfCQltDm/eac+z39PT008dEQKQ05q2FwBQD4EDiRE4kBiBA4kROJAYgQOJETiQGIEDiRE4kFi3xtC1nYEY6NtcfvD0hfIzJdV4NZ/Xri0+U5KmXtlXZe7rtj5bZe6p2cEqc2vY1p2qMvepC+uLzzz7zISmnp9yr9tVCXygb7Nues3His+N8ePFZ0rS3FT5T2x3+KriMyXpr5/aVmXuAx++t8rcvaffUmVuDfdccbjK3E+O31R85o8/9vNGt+MhOpAYgQOJETiQGIEDiRE4kBiBA4k1Ctz2u20/bvuI7btrLwWgjJ6B2+5I+qak90jaJekjtnfVXgzA8jW5gr9V0pGIOBoR05IekHR73bUAlNAk8CFJT1/09vjC+/6H7d22R22PTs+eL7UfgGVoEvhLvd71RS/ejog9ETESESNrOwPL3wzAsjUJfFzS9oveHpb0TJ11AJTUJPA/SrrG9k7bayXdIemnddcCUELP3yaLiBnbn5H0S0kdSd+LiEPVNwOwbI1+XTQiHpb0cOVdABTGK9mAxAgcSIzAgcQIHEiMwIHEqhy6qNlZ6dTp4mMnb3tj8ZmSNDNY/uvcuVfX+do5t63Oy4B/cubNVeY++MSbqswd3lz+/vXtvvIzJel3x15bfObZ6f5Gt+MKDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kVuVU1dmN63TmXdcUn3vixpf6U+XL133NRPGZMzOd4jMl6crLzlSZ+7fJK6rMPXtqsMrcJw5uLT7za+uuKj5TkmY3zhWfGRea3b+4ggOJETiQGIEDiRE4kBiBA4kROJBYz8Btb7f9G9tjtg/Zvuv/sRiA5Wvyc/AZSV+MiP22N0p61PavIuJw5d0ALFPPK3hEHI+I/Qv/flbSmKSh2osBWL4lfQ9ue4ek6yXtq7EMgLIaB257g6QHJX0+Il70eknbu22P2h698O9zJXcE8DI1Ctx2n+bjvj8iHnqp20TEnogYiYiRvv4NJXcE8DI1eRbdkr4raSwi7q2/EoBSmlzBb5b0UUm32D648M97K+8FoICePyaLiN9LqvN7mgCq4pVsQGIEDiRG4EBiBA4kRuBAYnUOXeyXTl1T/tBBz0XxmZL0ik3lD1189rlNxWdKUt+a8gf4SdL4xJYqczVV5/DJy/80W3zmme11dj03PF1+aKfZ/YArOJAYgQOJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQWJVTVWONNNdffm73XJ0/kXbin5uLz4zTa4vPlKSpLVU+ZZqaqTO3M1HnGtKdLH+qqufqnKrav+5C8Zle0+yEYa7gQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGKNA7fdsX3A9s9qLgSgnKVcwe+SNFZrEQDlNQrc9rCk90m6r+46AEpqegX/uqQvSbrkXx23vdv2qO3R2YmJIssBWJ6egdt+v6R/RMSji90uIvZExEhEjHTWry+2IICXr8kV/GZJH7D9pKQHJN1i+wdVtwJQRM/AI+LLETEcETsk3SHp1xFxZ/XNACwbPwcHElvSLwFHxG8l/bbKJgCK4woOJEbgQGIEDiRG4EBiBA4kVuUozf4N09r5zieLz/3bH64qPlOSBv80UHzmzGDxkZKkyaG+KnPn5lbX1/rnry7/cZi6otlJpUs1PVn+hN1o+PlaXZ9VAEtC4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kVuVU1enZjsZPby4+t++ci8+UpHUny5+mOXllnV37u7NV5l572fEqc4+su7zK3Gc3bi0+0zN1rnedE/3lh15odv/iCg4kRuBAYgQOJEbgQGIEDiRG4EBijQK3vcX2Xtt/sT1m+6baiwFYvqY/B/+GpF9ExIdsr5VU6W9nAiipZ+C2N0l6h6SPS1JETEuarrsWgBKaPES/WtJJSd+3fcD2fbbXV94LQAFNAu9KukHStyLiekkTku5+4Y1s77Y9ant09sxk4TUBvBxNAh+XNB4R+xbe3qv54P9HROyJiJGIGOls4lt0YCXoGXhEnJD0tO1rF951q6TDVbcCUETTZ9E/K+n+hWfQj0r6RL2VAJTSKPCIOChppPIuAArjlWxAYgQOJEbgQGIEDiRG4EBiBA4kVuVU1bk5a3Ky/EmSc0N1ThQ9f93q+d2ZLd2ZKnN3bahzquqOwX9Vmbv33JuLz5w9uqH4TEma6y9/aq8aHtrLFRxIjMCBxAgcSIzAgcQIHEiMwIHECBxIjMCBxAgcSIzAgcQIHEiMwIHECBxIjMCBxAgcSIzAgcQIHEiMwIHECBxIjMCBxKocurh14Lw++IaDxef+6LEX/dXiIgYGyx+6uGbNXPGZkrShr84BkU9NXVZl7uPPv6rK3G63/Mf3yhvqHDzZ3yl/UOa/BprdD7iCA4kROJAYgQOJETiQGIEDiRE4kBiBA4k1Ctz2F2wfsv1n2z+0va72YgCWr2fgtockfU7SSERcJ6kj6Y7aiwFYvqYP0buSBmx3JQ1KeqbeSgBK6Rl4RPxd0lclHZN0XNLpiHjkhbezvdv2qO3RyVP/Lr8pgCVr8hB9q6TbJe2UtE3Sett3vvB2EbEnIkYiYmRwa3/5TQEsWZOH6LdJeiIiTkbEBUkPSXpb3bUAlNAk8GOSbrQ9aNuSbpU0VnctACU0+R58n6S9kvZLemzhv9lTeS8ABTT6ffCIuEfSPZV3AVAYr2QDEiNwIDECBxIjcCAxAgcSq3Kq6pmT6/XId8q/FubK5+qcVHri7X3FZw6++lzxmZJ0/OzGKnOfOz9YZe756fIfW0m6fMNE8ZkfHDpQfKYknZ0t/8uXh7vNXg7OFRxIjMCBxAgcSIzAgcQIHEiMwIHECBxIjMCBxAgcSIzAgcQIHEiMwIHECBxIjMCBxAgcSIzAgcQIHEiMwIHECBxIjMCBxAgcSMwRUX6ofVLSUw1uermkfxZfoJ7VtO9q2lVaXfuuhF2viogret2oSuBN2R6NiJHWFlii1bTvatpVWl37rqZdeYgOJEbgQGJtB76n5f//Uq2mfVfTrtLq2nfV7Nrq9+AA6mr7Cg6gotYCt/1u24/bPmL77rb26MX2dtu/sT1m+5Dtu9reqQnbHdsHbP+s7V0WY3uL7b22/7LwMb6p7Z0WY/sLC/eDP9v+oe3yf1mwoFYCt92R9E1J75G0S9JHbO9qY5cGZiR9MSLeIOlGSZ9ewbte7C5JY20v0cA3JP0iIl4v6U1awTvbHpL0OUkjEXGdpI6kO9rdanFtXcHfKulIRByNiGlJD0i6vaVdFhURxyNi/8K/n9X8HXCo3a0WZ3tY0vsk3df2LouxvUnSOyR9V5IiYjoinm93q566kgZsdyUNSnqm5X0W1VbgQ5Kevujtca3waCTJ9g5J10va1+4mPX1d0pck1fmD6uVcLemkpO8vfDtxn+31bS91KRHxd0lflXRM0nFJpyPikXa3Wlxbgfsl3rein863vUHSg5I+HxFn2t7nUmy/X9I/IuLRtndpoCvpBknfiojrJU1IWsnPx2zV/CPNnZK2SVpv+852t1pcW4GPS9p+0dvDWsEPdWz3aT7u+yPiobb36eFmSR+w/aTmv/W5xfYP2l3pksYljUfEfx8R7dV88CvVbZKeiIiTEXFB0kOS3tbyTotqK/A/SrrG9k7bazX/RMVPW9plUbat+e8RxyLi3rb36SUivhwRwxGxQ/Mf119HxIq8ykTECUlP27524V23Sjrc4kq9HJN0o+3BhfvFrVrBTwpK8w+R/u8iYsb2ZyT9UvPPRH4vIg61sUsDN0v6qKTHbB9ceN9XIuLhFnfK5LOS7l/4Qn9U0ida3ueSImKf7b2S9mv+pysHtMJf1cYr2YDEeCUbkBiBA4kROJAYgQOJETiQGIEDiRE4kBiBA4n9BxUPuPwj2mf8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe3c6681ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class PlanetScopeDataset(Dataset):\n",
    "    \"\"\"DG Dataset\"\"\"\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            image_dir(string): the folder containing the DG images\n",
    "            transform (callable, optional): Optional transform to  be applies\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = glob.glob(self.image_dir + '/*.tif')[idx]\n",
    "        img_arr = getDims(img_name)[1]\n",
    "        \n",
    "        img_arr = img_arr / 10000\n",
    "        \n",
    "        if self.transform:\n",
    "            img_arr = self.transform(img_arr)\n",
    "        \n",
    "        return img_arr\n",
    "    \n",
    "pl_dataset = PlanetScopeDataset(planet_dir)\n",
    "sample = pl_dataset[1]\n",
    "plt.imshow(sample[0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make a class to transform the array to a tensor, and make the dataset calls use it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jomc9287/anaconda3/envs/pytorch35/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: The value of this property will change in version 1.0. Please see https://github.com/mapbox/rasterio/issues/86 for details.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 30, 30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays to Tensors... \n",
    "    NOTE: rasterio has band as first dim, no need for transpose\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(self, img_arr):\n",
    "        return torch.from_numpy(img_arr)\n",
    "    \n",
    "pl_T_dataset = PlanetScopeDataset(planet_dir, transform=transforms.Compose([ToTensor()]))\n",
    "dg_T_dataset = DigitalGlobeDataset(dg_dir, transform=transforms.Compose([ToTensor()]))\n",
    "\n",
    "dg_T_dataset[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, upscale_factor, NUMBER_OF_BANDS):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(NUMBER_OF_BANDS, 64, (5, 5), (1, 1), (2, 2))      # Here \n",
    "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv4 = nn.Conv2d(32, ((NUMBER_OF_BANDS) * (upscale_factor ** 2)),  # And here\n",
    "                               (3, 3), (1, 1), (1, 1))\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pixel_shuffle(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        init.orthogonal(self.conv1.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal(self.conv2.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal(self.conv3.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal(self.conv4.weight)\n",
    "\n",
    "## define the model for this case\n",
    "model = Net(upscale_factor=3, NUMBER_OF_BANDS=4)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=.01) # learning rate is 0.01\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the DataLoaders for training, testing, and validation \n",
    "#### (training_data_loader, test_data_loader, and val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use the PyTorch super-resolution example for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, training_list, input_dataset, target_dataset):  # updated to include list of inds, Datasets\n",
    "    epoch_loss = 0\n",
    "#     for iteration, batch in enumerate(training_data_loader, 1):\n",
    "#         input, target = Variable(batch[0]), Variable(batch[1])\n",
    "        \n",
    "    random.shuffle(training_list) # shuffle the list\n",
    "    for iteration, ind in enumerate(training_list)\n",
    "        input, target = Variable(input_dataset[ind].unsqueeze(0).float()), \\\n",
    "                        Variable(target_dataset[ind].unsqueeze(0).float())\n",
    "        \n",
    "        if cuda:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(input), target)\n",
    "        epoch_loss += loss.data[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"===> Epoch[{}]({}/{}): Loss: {:.4f}\".format(epoch, iteration, len(training_list), loss.data[0]))\n",
    "\n",
    "    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(training_list))\n",
    "\n",
    "\n",
    "def test(testing_list, input_dataset, target_dataset):\n",
    "    avg_psnr = 0\n",
    "#     for batch in testing_data_loader:\n",
    "#         input, target = Variable(batch[0]), Variable(batch[1])\n",
    "        \n",
    "        random.shuffle(testing_list)\n",
    "        for iteration, ind in enumerate(testing_list)\n",
    "          input, target = Variable(input_dataset[ind].unsqueeze(0).float()), \\\n",
    "                        Variable(target_dataset[ind].unsqueeze(0).float())\n",
    "          if cuda:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        prediction = model(input)\n",
    "        mse = criterion(prediction, target)\n",
    "        psnr = 10 * log10(1 / mse.data[0])\n",
    "        avg_psnr += psnr\n",
    "    print(\"===> Avg. PSNR: {:.4f} dB\".format(avg_psnr / len(testing_data_loader)))\n",
    "\n",
    "\n",
    "def checkpoint(epoch):\n",
    "    model_out_path = \"/media/jomc9287/Data/pytorch_SSIR_jdiaz/pytorch_outputs/model_epoch_{}.pth\".format(epoch)\n",
    "    torch.save(model, model_out_path)\n",
    "    print(\"Checkpoint saved to {}\".format(model_out_path))\n",
    "\n",
    "# define the number of epochs\n",
    "num_epochs = 30\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(epoch, train_list, pl_T_dataset, dg_T_dataset)\n",
    "    test(test_list, pl_T_dataset, dg_T_dataset)\n",
    "    checkpoint(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jomc9287/anaconda3/envs/pytorch35/lib/python3.5/site-packages/ipykernel_launcher.py:6: FutureWarning: The value of this property will change in version 1.0. Please see https://github.com/mapbox/rasterio/issues/86 for details.\n",
      "  \n",
      "/home/jomc9287/anaconda3/envs/pytorch35/lib/python3.5/site-packages/ipykernel_launcher.py:7: FutureWarning: The value of this property will change in version 1.0. Please see https://github.com/mapbox/rasterio/issues/86 for details.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "## read the data for all of the files\n",
    "# training_pl = [getDims(f) for f in planet_files[:train_len+1]]\n",
    "# test_pl = [getDims(f) for f in planet_files[train_len:train_len + test_len + 1]]\n",
    "# validation_pl = [getDims(f) for f in planet_files[train_len + test_len:]]\n",
    "\n",
    "# training_dg = [getDims(f) for f in dg_files[:train_len+1]]\n",
    "# test_dg = [getDims(f) for f in dg_files[train_len:train_len + test_len + 1]]\n",
    "# validation_dg = [getDims(f) for f in dg_files[train_len + test_len:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to extract the BGRN bands from the DG arrays\n",
    "# bgrn = [1,2,4,6]\n",
    "# training_dg_arr = [tup[1][bgrn,:,:] for tup in training_dg]\n",
    "# test_dg_arr = [tup[1][bgrn,:,:] for tup in test_dg]\n",
    "# validation_dg_arr = [tup[1][bgrn,:,:] for tup in validation_dg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## then, need to resize DG arrays to planet array shapes\n",
    "# pl_shp = training_pl[0][1].shape\n",
    "# upscale_factor = 3\n",
    "# new_shp = (pl_shp[0], pl_shp[1]*upscale_factor, pl_shp[2]*upscale_factor)\n",
    "# training_dg_rs = [resize(im, new_shp, preserve_range=True, mode='reflect') for im in training_dg_arr]\n",
    "# test_dg_rs = [resize(im, new_shp, preserve_range=True, mode='reflect') for im in test_dg_arr]\n",
    "# validation_dg_rs = [resize(im, new_shp, preserve_range=True, mode='reflect') for im in validation_dg_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract the planet arrays\n",
    "# training_pl_arr = [tup[1] for tup in training_pl]\n",
    "# test_pl_arr = [tup[1] for tup in test_pl]\n",
    "# validation_pl_arr = [tup[1] for tup in validation_pl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### need to normalize the data in the array by something... max()? Maximum bit value, e.g., 2^11?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale_factor = 10000 # this is used to normalize to surface reflectance as per file metadata\n",
    "# trX = torch.from_numpy(np.asarray(training_pl_arr).astype('float')) / scale_factor\n",
    "# trY = torch.from_numpy(np.asarray(training_dg_rs).astype('float')) / scale_factor\n",
    "\n",
    "# teX = torch.from_numpy(np.asarray(test_pl_arr).astype('float')) / scale_factor\n",
    "# teY = torch.from_numpy(np.asarray(test_dg_rs).astype('float')) / scale_factor\n",
    "\n",
    "# valX = torch.from_numpy(np.asarray(validation_pl_arr).astype('float')) / scale_factor\n",
    "# valY = torch.from_numpy(np.asarray(validation_dg_rs).astype('float')) / scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "## test the model\n",
    "# testing = valX[0].unsqueeze(0) # the .unsqueeze(0) ensure batch dim == 1, eg., [1,bands,rows,cols]\n",
    "# testing = Variable(testing)\n",
    "# testing = testing.float()\n",
    "# output = model(testing)\n",
    "# print(output.size())\n",
    "\n",
    "# # visualize it\n",
    "# arr_random = output.data.numpy()\n",
    "# arr_random = arr.squeeze()\n",
    "# # plt.imshow(arr[0,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python PyTorch35",
   "language": "python",
   "name": "pytorch35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
